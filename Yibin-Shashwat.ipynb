{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT561 Final Project (Fall 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Please be creative in defining the new variables as part of the data manipulation and write your description at the end of each code as the comment. We will read your logic and description for the assessment.\n",
    "\n",
    "\n",
    "**Part 1**: \n",
    "75 points (85 points with the extra credits in the Bonus Question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode bytes in position 2501-2502: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m file_path2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrder_details.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m Property_details \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path1)\n\u001b[1;32m----> 9\u001b[0m Order_details \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     78\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:547\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:636\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1965\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode bytes in position 2501-2502: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "file_path1 = \"Property_details.csv\"\n",
    "file_path2 = \"Order_details.csv\"\n",
    "\n",
    "\n",
    "Property_details = pd.read_csv(file_path1)\n",
    "Order_details = pd.read_csv(file_path2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "**Part (a)**: How many properties are there in the region with the zip code of 84600? \n",
    "\n",
    "**Part (b)**: What is the mean, standard deviation, median, min, and max of “starratings” for all properties in the region with the zip code of 84600?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of properties in the region with the zip code 84600 is: 104\n"
     ]
    }
   ],
   "source": [
    "# Part (a):\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"Property_details.csv\"  # Replace with the actual path\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "property_details = pd.read_csv(file_path)\n",
    "\n",
    "# Filter properties with the zip code of 84600\n",
    "zip_code_filter = property_details['zipcode'] == 84600\n",
    "properties_in_region = property_details[zip_code_filter]\n",
    "\n",
    "# Get the count of properties in the specified region\n",
    "num_properties_in_region = len(properties_in_region)\n",
    "\n",
    "# Print the result\n",
    "print(f'The number of properties in the region with the zip code 84600 is: {num_properties_in_region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Rating: 3.4615384615384617\n",
      "Standard Deviation Rating: 0.7094791871175287\n",
      "Median Rating: 4.0\n",
      "Minimum Rating: 2\n",
      "Maximum Rating: 4\n"
     ]
    }
   ],
   "source": [
    "# Part (b):\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"Property_details.csv\"  # Replace with the actual path\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "property_details = pd.read_csv(file_path)\n",
    "\n",
    "# Filter properties with the zip code of 84600\n",
    "zip_code_filter = property_details['zipcode'] == 84600\n",
    "properties_in_region = property_details[zip_code_filter]\n",
    "\n",
    "# Calculate statistics for the \"starratings\" column\n",
    "mean_rating = properties_in_region['starrating'].mean()\n",
    "std_dev_rating = properties_in_region['starrating'].std()\n",
    "median_rating = properties_in_region['starrating'].median()\n",
    "min_rating = properties_in_region['starrating'].min()\n",
    "max_rating = properties_in_region['starrating'].max()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean Rating: {mean_rating}\")\n",
    "print(f\"Standard Deviation Rating: {std_dev_rating}\")\n",
    "print(f\"Median Rating: {median_rating}\")\n",
    "print(f\"Minimum Rating: {min_rating}\")\n",
    "print(f\"Maximum Rating: {max_rating}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "**Part (a)**: Create a new column called \"weekday\", which is the day of the “reservation date” in one week (for example, if the reservation date is 2021/10/22, the corresponding value in the new column \"weekday\" should be “Fri”).\n",
    "\n",
    "**Part (b)**: Which weekday receives an above-average number of reservations compared to all records?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  propertycode       dtcollected reservation date  los  guests  \\\n",
      "0  50677497        634876  10/12/2019 15:46       2019-11-02    1       1   \n",
      "\n",
      "      roomtype  onsiteprice                                 ratedescription  \\\n",
      "0  Double Room        82.36  Room size: 15 mÂ²/161 ftÂ², Shower, 1 king bed   \n",
      "\n",
      "              ratetype  ... maxoccupancy ispromo  closed discount promoname  \\\n",
      "0  Cancellation policy  ...            1       Y       N     6.24       NaN   \n",
      "\n",
      "                            proxyused mealinclusiontype hotelblock  \\\n",
      "0  media:M3diAproxy@173.44.165.126:80    Free Breakfast        NaN   \n",
      "\n",
      "  input_dtcollected weekday  \n",
      "0        10/13/2019     Sat  \n",
      "\n",
      "[1 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Part (a):\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"Order_details.csv\"  # Replace with the actual path\n",
    "\n",
    "# Read the CSV file into a DataFrame with a specified encoding\n",
    "order_details = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Convert the \"reservation date\" column to datetime format\n",
    "order_details['reservation date'] = pd.to_datetime(order_details['reservation date'])\n",
    "\n",
    "# Create a new column \"weekday\" based on the day of the week\n",
    "order_details['weekday'] = order_details['reservation date'].dt.strftime('%a')\n",
    "\n",
    "# Print the DataFrame to verify the changes\n",
    "print(order_details.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekdays with above-average number of reservations: Mon, Thu, Tue, Wed\n"
     ]
    }
   ],
   "source": [
    "# Part (b):\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"Order_details.csv\"  # Replace with the actual path\n",
    "\n",
    "# Read the CSV file into a DataFrame with a specified encoding\n",
    "order_details = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Convert the \"reservation date\" column to datetime format\n",
    "order_details['reservation date'] = pd.to_datetime(order_details['reservation date'])\n",
    "\n",
    "# Create a new column \"weekday\" based on the day of the week\n",
    "order_details['weekday'] = order_details['reservation date'].dt.strftime('%a')\n",
    "\n",
    "# Calculate the average number of reservations across all weekdays\n",
    "average_reservations = order_details.groupby('weekday').size().mean()\n",
    "\n",
    "# Identify weekdays with above-average reservations\n",
    "above_average_weekdays = order_details.groupby('weekday').size()[order_details.groupby('weekday').size() > average_reservations].index\n",
    "\n",
    "# Print the result\n",
    "print(f\"Weekdays with above-average number of reservations: {', '.join(above_average_weekdays)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "**Part (a)**: In “roomamenities”, what are the top 10 common room amenities in single rooms (rooms with a maxoccupancy of 1)? A what about the 10 least common room amenities in single rooms? (For example, Air conditioning is one amenity)\n",
    "\n",
    "**Part (b)**: What percentage does each type of room amenities occupy of the total number of reservations for single rooms?(Do not use the total number of amenities as denominator）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Common Room Amenities in Single Rooms:\n",
      "Air conditioning: ;Free Wi-Fi in all rooms!: ;In-room safe box: ;Shower: ;TV: ;                                                              12385\n",
      "Air conditioning: ;Free Wi-Fi in all rooms!: ;In-room safe box: ;Shower: ;Telephone: ;TV: ;                                                   2479\n",
      "Air conditioning: ;In-room safe box: ;Shower: ;TV: ;                                                                                           323\n",
      "Air conditioning: ;Closet: ;Free Wi-Fi in all rooms!: ;In-room safe box: ;Ironing facilities: ;Shower: ;TV: ;                                  277\n",
      "Air conditioning: ;Free Wi-Fi in all rooms!: ;In-room safe box: ;Shower: ;TV: ;Wi-Fi in public areas: ;                                        165\n",
      "Air conditioning: ;Closet: ;Free Wi-Fi in all rooms!: ;In-room safe box: ;Ironing facilities: ;Shower: ;Telephone: ;TV: ;                      125\n",
      "Air conditioning: ;Free Wi-Fi in all rooms!: ;In-room safe box: ;Shower: ;TV [flat screen]: ;                                                  124\n",
      "Air conditioning: ;Coffee/tea maker: ;Free Wi-Fi in all rooms!: ;Hair dryer: ;In-room safe box: ;Satellite/cable channels: ;Shower: ;          110\n",
      "Air conditioning: ;Free Wi-Fi in all rooms!: ;In-room safe box: ;Telephone: ;TV: ;                                                              98\n",
      "Air conditioning: ;Free Wi-Fi in all rooms!: ;Hair dryer: ;In-room safe box: ;Mini bar: ;Satellite/cable channels: ;Shower: ;Telephone: ;       94\n",
      "Name: roomamenities, dtype: int64\n",
      "\n",
      "10 Least Common Room Amenities in Single Rooms:\n",
      "Air conditioning: ;Free Wi-Fi in all rooms!: ;Hair dryer: ;Heating: ;In-room safe box: ;Telephone: ;TV [flat screen]: ;Wake-up service: ;                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
      "Additional bathroom: ;Additional toilet: ;Air conditioning: ;Carpeting: ;Cleaning products: ;Closet: ;Clothes dryer: ;Clothes rack: ;Desk: ;Dishwasher: ;DVD/CD player: ;Extra long bed: ;Fireplace: ;Free Wi-Fi in all rooms!: ;Full kitchen: ;Hair dryer: ;Heating: ;In-room safe box: ;Ironing facilities: ;Kitchenware: ;Laptop safe box: ;Linens: ;Microwave: ;On-demand movies: ;Private entrance: ;Refrigerator: ;Satellite/cable channels: ;Seating area: ;Separate dining area: ;Smoke detector: ;Sofa: ;Toiletries: ;Towels: ;Washing machine: ;Wooden/parqueted flooring: ;    1\n",
      "Air conditioning: ;Closet: ;Dart board: ;Desk: ;Free bottled water: ;Free Wi-Fi in all rooms!: ;Hair dryer: ;Heating: ;In-room safe box: ;Mini bar: ;Satellite/cable channels: ;Seating area: ;Smoke detector: ;Soundproofing: ;Telephone: ;Toiletries: ;Towels: ;Wake-up service: ;                                                                                                                                                                                                                                                                                                      1\n",
      "Air conditioning: ;Closet: ;Desk: ;Free bottled water: ;Free Wi-Fi in all rooms!: ;Hair dryer: ;Heating: ;In-room safe box: ;Mini bar: ;Satellite/cable channels: ;Smoke detector: ;Soundproofing: ;Telephone: ;Toiletries: ;Towels: ;                                                                                                                                                                                                                                                                                                                                                    1\n",
      "Additional toilet: ;Air conditioning: ;Closet: ;Clothes rack: ;Desk: ;Free Wi-Fi in all rooms!: ;Hair dryer: ;Heating: ;In-room safe box: ;Mini bar: ;Smoke detector: ;Soundproofing: ;Telephone: ;Toiletries: ;Towels: ;TV [flat screen]: ;Wake-up service: ;Wooden/parqueted flooring: ;                                                                                                                                                                                                                                                                                                1\n",
      "Air conditioning: ;Desk: ;Free Wi-Fi in all rooms!: ;Hair dryer: ;Heating: ;In-room safe box: ;Mini bar: ;Satellite/cable channels: ;Seating area: ;Shower: ;Telephone: ;Toiletries: ;Wake-up service: ;                                                                                                                                                                                                                                                                                                                                                                                  1\n",
      "Additional bathroom: ;Air conditioning: ;Closet: ;Coffee/tea maker: ;Desk: ;Free Wi-Fi in all rooms!: ;Full kitchen: ;Hair dryer: ;Heating: ;High chair: ;In-room safe box: ;Interconnecting room(s) available: ;Kitchenware: ;Linens: ;Microwave: ;Refrigerator: ;Seating area: ;Separate dining area: ;Smoke detector: ;Sofa: ;Telephone: ;Toiletries: ;Towels: ;TV [flat screen]: ;Wake-up service: ;Wooden/parqueted flooring: ;                                                                                                                                                      1\n",
      "Additional toilet: ;Air conditioning: ;Alarm clock: ;Carpeting: ;Closet: ;Coffee/tea maker: ;Desk: ;Free Wi-Fi in all rooms!: ;Hair dryer: ;Heating: ;In-room safe box: ;Ironing facilities: ;Linens: ;Seating area: ;Toiletries: ;Towels: ;TV [flat screen]: ;Wake-up service: ;                                                                                                                                                                                                                                                                                                         1\n",
      "Air conditioning: ;Closet: ;Desk: ;Free Wi-Fi in all rooms!: ;Hair dryer: ;Heating: ;In-room safe box: ;Satellite/cable channels: ;Smoke detector: ;Soundproofing: ;Telephone: ;Toiletries: ;Towels: ;Wake-up service: ;Wooden/parqueted flooring: ;                                                                                                                                                                                                                                                                                                                                      1\n",
      "Air conditioning: ;Bathrobes: ;Carpeting: ;Closet: ;Desk: ;Extra long bed: ;Free Wi-Fi in all rooms!: ;Hair dryer: ;Heating: ;High chair: ;In-room safe box: ;Ironing facilities: ;Linens: ;Mini bar: ;Mirror: ;Mosquito net: ;Satellite/cable channels: ;Telephone: ;Toiletries: ;Towels: ;Wake-up service: ;                                                                                                                                                                                                                                                                            1\n",
      "Name: roomamenities, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# You can deceide whether to display you output for 3(a) and 3(b) separately or together\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"Order_details.csv\"  # Replace with the actual path\n",
    "\n",
    "# Read the CSV file into a DataFrame with a specified encoding\n",
    "order_details = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Filter rows for single rooms (maxoccupancy = 1)\n",
    "single_rooms = order_details[order_details['maxoccupancy'] == 1]\n",
    "\n",
    "# Split and explode the \"roomamenities\" column to create a list of amenities\n",
    "amenities_series = single_rooms['roomamenities'].str.split(',').explode()\n",
    "\n",
    "# Remove leading and trailing whitespaces from amenities\n",
    "amenities_series = amenities_series.str.strip()\n",
    "\n",
    "# Calculate the top 10 common room amenities\n",
    "top_10_common_amenities = amenities_series.value_counts().head(10)\n",
    "\n",
    "# Calculate the 10 least common room amenities\n",
    "least_10_common_amenities = amenities_series.value_counts().tail(10)\n",
    "\n",
    "# Print the results\n",
    "print(\"Top 10 Common Room Amenities in Single Rooms:\")\n",
    "print(top_10_common_amenities)\n",
    "\n",
    "print(\"\\n10 Least Common Room Amenities in Single Rooms:\")\n",
    "print(least_10_common_amenities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " If you displayed your output of 3(b) together with 3(a) please delete this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "**Part (a)**: For each property, there are some abnormal values of 0 in the “onsiteprice”. To better organize the data, you would like to create a new column “replaced onsiteprice” in the dataset by retaining the original non-zero “onsiteprice” of one specific property and replacing the zero value with its median of non-zero “onsiteprice”.\n",
    "\n",
    "**Part (b)**: For each property, calculate the maximum and minimum value of “replaced onsiteprice”, and store these two into corresponding two columns named “Maximum” and “Minimum”. Then create a column named “Normalized Maximum” to store the normalized form of the “Maximum” column. You can use the formula below for the normalization (do not round the result). Store the “hotelcode”, “Maximum”, “Minimum”, “Normalized Maximum” to \"Max_Min Price.csv\". \n",
    "$ X_{norm} = \\frac{X-X_{min}}{X_\\max-X_{min}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  propertycode       dtcollected reservation date  los  guests  \\\n",
      "0  50677497        634876  10/12/2019 15:46        11/2/2019    1       1   \n",
      "1  50672149       8328096  10/12/2019 15:47       11/30/2019    1       1   \n",
      "2  50643430       8323442  10/12/2019 15:47       12/20/2019    1       1   \n",
      "3  50650317          7975  10/12/2019 15:47       12/28/2019    1       1   \n",
      "4  50650318          7975  10/12/2019 15:47       12/28/2019    1       1   \n",
      "\n",
      "               roomtype  onsiteprice  \\\n",
      "0           Double Room        82.36   \n",
      "1         Vacation Home       636.09   \n",
      "2         Vacation Home       591.74   \n",
      "3  Standard Triple Room       881.48   \n",
      "4  Standard Triple Room       897.53   \n",
      "\n",
      "                                     ratedescription  \\\n",
      "0     Room size: 15 mÂ²/161 ftÂ², Shower, 1 king bed   \n",
      "1  Shower, Kitchenette, 2 bedrooms, 1 double bed ...   \n",
      "2  Shower, Kitchenette, 2 bedrooms, 1 double bed ...   \n",
      "3  Room size: 20 mÂ²/215 ftÂ², Shower, 3 single beds   \n",
      "4  Room size: 20 mÂ²/215 ftÂ², Shower, 3 single beds   \n",
      "\n",
      "                            ratetype  ... maxoccupancy ispromo  closed  \\\n",
      "0                Cancellation policy  ...            1       Y       N   \n",
      "1                Cancellation policy  ...            4       N       N   \n",
      "2  Extra low price! (non-refundable)  ...            4       N       N   \n",
      "3  Extra low price! (non-refundable)  ...            1       N       N   \n",
      "4  Extra low price! (non-refundable)  ...            3       N       N   \n",
      "\n",
      "  discount promoname                            proxyused  \\\n",
      "0     6.24       NaN   media:M3diAproxy@173.44.165.126:80   \n",
      "1     0.00       NaN   media:M3diAproxy@173.44.164.126:80   \n",
      "2     0.00       NaN   media:M3diAproxy@173.44.166.122:80   \n",
      "3     0.00       NaN  media:M3diAproxy@209.242.219.141:80   \n",
      "4     0.00       NaN  media:M3diAproxy@209.242.219.141:80   \n",
      "\n",
      "        mealinclusiontype hotelblock input_dtcollected replaced_onsiteprice  \n",
      "0          Free Breakfast        NaN        10/13/2019                82.36  \n",
      "1                     NaN        NaN        10/13/2019               636.09  \n",
      "2                     NaN        NaN        10/13/2019               591.74  \n",
      "3                     NaN        NaN        10/13/2019               881.48  \n",
      "4  Free breakfast for {3}        NaN        10/13/2019               897.53  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Part (a):\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"Order_details.csv\"  # Replace with the actual path\n",
    "\n",
    "# Read the CSV file into a DataFrame with a specified encoding\n",
    "order_details = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Filter rows with zero \"onsiteprice\" values\n",
    "zero_price_filter = order_details['onsiteprice'] == 0\n",
    "\n",
    "# Create a new column \"replaced_onsiteprice\" by copying the original \"onsiteprice\"\n",
    "order_details['replaced_onsiteprice'] = order_details['onsiteprice']\n",
    "\n",
    "# Calculate the median of non-zero \"onsiteprice\" for each property\n",
    "property_median_prices = order_details[order_details['onsiteprice'] > 0].groupby('propertycode')['onsiteprice'].median()\n",
    "\n",
    "# Replace zero values in \"replaced_onsiteprice\" with the median for the corresponding property\n",
    "order_details.loc[zero_price_filter, 'replaced_onsiteprice'] = order_details.loc[zero_price_filter, 'propertycode'].map(property_median_prices)\n",
    "\n",
    "# Print the DataFrame to verify the changes\n",
    "print(order_details.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   hotelcode  Maximum  Minimum  Normalized Maximum\n",
      "0         31   374.73   219.52            0.008631\n",
      "1         56   149.51    73.46            0.004229\n",
      "2         97   468.83   259.76            0.011626\n",
      "3        138   321.84   169.66            0.008463\n",
      "4        147   226.18   122.90            0.005743\n"
     ]
    }
   ],
   "source": [
    "# Part (b):\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"Order_details.csv\"  # Replace with the actual path\n",
    "\n",
    "# Read the CSV file into a DataFrame with a specified encoding\n",
    "order_details = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Filter rows with zero \"onsiteprice\" values\n",
    "zero_price_filter = order_details['onsiteprice'] == 0\n",
    "\n",
    "# Create a new column \"replaced_onsiteprice\" by copying the original \"onsiteprice\"\n",
    "order_details['replaced_onsiteprice'] = order_details['onsiteprice']\n",
    "\n",
    "# Calculate the median of non-zero \"onsiteprice\" for each property\n",
    "property_median_prices = order_details[order_details['onsiteprice'] > 0].groupby('propertycode')['onsiteprice'].median()\n",
    "\n",
    "# Replace zero values in \"replaced_onsiteprice\" with the median for the corresponding property\n",
    "order_details.loc[zero_price_filter, 'replaced_onsiteprice'] = order_details.loc[zero_price_filter, 'propertycode'].map(property_median_prices)\n",
    "\n",
    "# Calculate maximum and minimum values of \"replaced_onsiteprice\" for each property\n",
    "property_price_stats = order_details.groupby('propertycode')['replaced_onsiteprice'].agg(['max', 'min']).reset_index()\n",
    "property_price_stats.columns = ['hotelcode', 'Maximum', 'Minimum']\n",
    "\n",
    "# Calculate the Normalized Maximum column\n",
    "property_price_stats['Normalized Maximum'] = (property_price_stats['Maximum'] - property_price_stats['Minimum']) / (property_price_stats['Maximum'] - property_price_stats['Minimum']).max()\n",
    "\n",
    "# Save relevant columns to a new CSV file\n",
    "property_price_stats[['hotelcode', 'Maximum', 'Minimum', 'Normalized Maximum']].to_csv(\"Max_Min_Price.csv\", index=False)\n",
    "\n",
    "# Print the DataFrame to verify the changes\n",
    "print(property_price_stats.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "**Part (a)**: A party of three is planning a trip. How many available hotels do offer a room with the “maxoccupancy” of 3 or more? Available hotel are those whose “propertype” are “Hotels”, “close” are “N”, and “hotelblock” are not “sold out” .\n",
    "\n",
    "**Part (b)**: If this party does not want to pay a room for a “replaced onsiteprice” higher than 150 per night, how many hotels are still available? Use the maximum of “replaced onsiteprice” to compare with 150 due to price fluctuation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of available hotels with a room for 3 or more guests is: 3141\n"
     ]
    }
   ],
   "source": [
    "# Part (a):\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"Order_details.csv\"  # Replace with the actual path\n",
    "\n",
    "# Read the CSV file into a DataFrame with a specified encoding\n",
    "order_details = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Filter hotels based on conditions\n",
    "available_hotels = order_details[(order_details['closed'] == 'N') &\n",
    "                                 (order_details['hotelblock'] != 'sold out') & \n",
    "                                 (order_details['maxoccupancy'] >= 3)]\n",
    "\n",
    "# Count the number of available hotels\n",
    "num_available_hotels = available_hotels['propertycode'].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(f\"The number of available hotels with a room for 3 or more guests is: {num_available_hotels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: replaced_onsiteprice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 32\u001b[0m\n\u001b[0;32m     25\u001b[0m order_details \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Filter hotels based on conditions, including the maximum price constraint\u001b[39;00m\n\u001b[0;32m     28\u001b[0m available_hotels \u001b[38;5;241m=\u001b[39m order_details[ \n\u001b[0;32m     29\u001b[0m                                  (order_details[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[0;32m     30\u001b[0m                                  (order_details[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhotelblock\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msold out\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[0;32m     31\u001b[0m                                  (order_details[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxoccupancy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m---> 32\u001b[0m                                  (\u001b[43morder_details\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpropertycode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreplaced_onsiteprice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m150\u001b[39m)]\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Count the number of available hotels\u001b[39;00m\n\u001b[0;32m     35\u001b[0m num_available_hotels \u001b[38;5;241m=\u001b[39m available_hotels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpropertycode\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:1416\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1408\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise warning\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexing with multiple keys (implicitly converted to a tuple \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1412\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof keys) will be deprecated, use a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1413\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   1414\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1415\u001b[0m     )\n\u001b[1;32m-> 1416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py:248\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m--> 248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m     subset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\n\u001b[0;32m    250\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m subset\u001b[38;5;241m.\u001b[39mndim\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Column not found: replaced_onsiteprice'"
     ]
    }
   ],
   "source": [
    "# Part (b):\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"Order_details.csv\"  # Replace with the actual path\n",
    "\n",
    "# Read the CSV file into a DataFrame with a specified encoding\n",
    "order_details = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Filter rows with zero \"onsiteprice\" values\n",
    "zero_price_filter = order_details['onsiteprice'] == 0\n",
    "\n",
    "# Create a new column \"replaced_onsiteprice\" by copying the original \"onsiteprice\"\n",
    "order_details['replaced_onsiteprice'] = order_details['onsiteprice']\n",
    "\n",
    "# Calculate the median of non-zero \"onsiteprice\" for each property\n",
    "property_median_prices = order_details[order_details['onsiteprice'] > 0].groupby('propertycode')['onsiteprice'].median()\n",
    "\n",
    "# Replace zero values in \"replaced_onsiteprice\" with the median for the corresponding property\n",
    "order_details.loc[zero_price_filter, 'replaced_onsiteprice'] = order_details.loc[zero_price_filter, 'propertycode'].map(property_median_prices)\n",
    "file_path = \"Order_details.csv\"  # Replace with the actual path\n",
    "\n",
    "# Read the CSV file into a DataFrame with a specified encoding\n",
    "order_details = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Filter hotels based on conditions, including the maximum price constraint\n",
    "available_hotels = order_details[ \n",
    "                                 (order_details['closed'] == 'N') & \n",
    "                                 (order_details['hotelblock'] != 'sold out') & \n",
    "                                 (order_details['maxoccupancy'] >= 3) & \n",
    "                                 (order_details.groupby('propertycode')['replaced_onsiteprice'].transform('max') <= 150)]\n",
    "\n",
    "# Count the number of available hotels\n",
    "num_available_hotels = available_hotels['propertycode'].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(f\"The number of available hotels with a room for 3 or more guests and a maximum price of $150 or less is: {num_available_hotels}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Question:\n",
    "\n",
    "Merge data, filter, groupby, merge three times\n",
    "\n",
    "**Part (a)**: For each country, find the most expensive property by using “replaced onsiteprice”. Provide id, name, rating, city, country, zip code, address, and average “replaced onsiteprice” of these properties.\n",
    "\n",
    "**Part (b)**: For each country, find the cheapest property by using “replaced onsiteprice”. Provide id, name, rating, city, country, zip code, address, and average “replaced onsiteprice” of these properties.\n",
    "\n",
    "**Hint**: Each country has numbers of hotels, and each hotel has numbers of prices due to price fluctuation. You need to find the average “replaced onsiteprice” for each hotel first, and sort out the cheapest and the most expensive hotels then.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (a):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part (b):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 (25 Points)\n",
    "\n",
    "For this part, we look at the logic and how you solve the problems. \n",
    "\n",
    "***Part (a):*** \n",
    "\n",
    "    1- You need to find \"5\" interesting business questions based on the datasets. Please make sure that these quastions are not similar with other groups...     \n",
    "    2- Write Python code to answer the questions.    \n",
    "    3- Visualize your results for each question. \n",
    "    \n",
    "\n",
    "***Part (b):***\n",
    "\n",
    "    Write a 300-word summary of your answers and business insights you get from answering these 5 questions based on your code. Ensure that you have clearly explained why we should care about your questions and your results. Clearly explain your findings.   \n",
    "\n",
    "***This part will be evaluated based on the following criteria:***\n",
    "\n",
    "    1. You need to ask five business-relevant questions. (5 points)\n",
    "    2. You need to answer these five questions using Python and the two datasets. (5 points)\n",
    "    3. You need to have at least \"5\" graphs to visualize your insights. (6 points)\n",
    "    4. Your executive summary should be well-written. (6 points)\n",
    "    5. Your results and business insights should be interesting and meaningful. (3 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: You may use this cell to write your 5 questions\n",
    "\n",
    "**Question 1:** \n",
    "\n",
    "**Question 2:** \n",
    "\n",
    "**Question 3:** \n",
    "\n",
    "**Question 4:** \n",
    "\n",
    "**Question 5:** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code to answer Question 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code to answer Question 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code to answer Question 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code to answer Question 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code to answer Question 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executive Summary & Business insights:\n",
    "\n",
    "\n",
    "**Note**: You need to use the Markdown cell below to write your executive summary & business insights.\n",
    "If you need more space use enter to go to the next line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading:\n",
    "\n",
    "PART 1 - 75 points (85 points with the extra credits in the Bonus Question)\n",
    "\n",
    "- Question 1: 9 points (6 points for part (a) and 3 points for part (b))\n",
    "- Question 2: 15 points (9 points for part (a) and 6 points for part (b))\n",
    "- Question 3: 12 points (9 points for part (a) and 3 points for part (b))\n",
    "- Question 4: 21 points (9 points for part (a) and 12 points for part (b))\n",
    "- Question 5: 18 points (9 points for part (a) and 9 points for part (b))\n",
    "- Bonus Question: 10 points (extra credit): (8 points for part (a) and 2 points for part (b))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PART 2 - 25 points \n",
    "- You need to ask five business-related questions (5 points).\n",
    "- You need to answer these five questions using Python and the two datasets (5 points).\n",
    "- You need to have at least \"5\" graphs to visualize your insights (6 points).\n",
    "- Your executive summary should be well-written (6 points).\n",
    "- Your results and business insights should be interesting and meaningful (3 points).\n",
    "\n",
    "\n",
    "Good Luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
